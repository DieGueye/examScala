{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f559f82b",
   "metadata": {},
   "source": [
    "*`Nom & Prenom : GUEYE DIE <br> Classe: M1 BI <br> Code: 220642"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5d5688",
   "metadata": {},
   "source": [
    "## Importation des modules Spark necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "89398cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                // Not required since almond 0.7.0 (will be automatically added when importing spark)\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                    \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{SparkSession, functions}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{SparkSession, DataFrame}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.{col, translate}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` // Or use any other 2.x version here\n",
    "import $ivy.`sh.almond::almond-spark:0.10.9` // Not required since almond 0.7.0 (will be automatically added when importing spark)\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.5`\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.{SparkSession, functions}\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame}\n",
    "import org.apache.spark.sql.functions.{col, translate}\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9ab891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrootLogger\u001b[39m: \u001b[32mLogger\u001b[39m = org.apache.log4j.spi.RootLogger@3d90ee57"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rootLogger = Logger.getRootLogger()\n",
    "rootLogger.setLevel(Level.ERROR)\n",
    "\n",
    "Logger.getLogger(\"org.apache.spark\").setLevel(Level.WARN)\n",
    "Logger.getLogger(\"org.spark-project\").setLevel(Level.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1607306",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57256c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775c4e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "23/05/26 11:39:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@c2a16d1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = {\n",
    "  SparkSession.builder()\n",
    "    .master(\"local\")\n",
    "    .appName(\"BD-FS FIRE\")\n",
    "    .config(\"spark.some.option.config\", \"config-value\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc641f33",
   "metadata": {},
   "source": [
    "## Pré-traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ac45a",
   "metadata": {},
   "source": [
    "### Chargement des données de Janvier - Décembre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caca522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdfJanuary\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfFebruary\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfMarch\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfApril\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfMay\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfJune\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfJuly\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfAugust\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfSeptembre\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfOctober\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfNovember\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]\n",
       "\u001b[36mdfDecember\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfJanuary = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_January_2019.csv\")\n",
    "val dfFebruary = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_February_2019.csv\")\n",
    "val dfMarch = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_March_2019.csv\")\n",
    "val dfApril = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_April_2019.csv\")\n",
    "val dfMay = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_May_2019.csv\")\n",
    "val dfJune = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_June_2019.csv\")\n",
    "val dfJuly = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_July_2019.csv\")\n",
    "val dfAugust = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_August_2019.csv\")\n",
    "val dfSeptembre = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_September_2019.csv\")\n",
    "val dfOctober = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_October_2019.csv\")\n",
    "val dfNovember = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_November_2019.csv\")\n",
    "val dfDecember = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Vente/Sales_December_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ea30a",
   "metadata": {},
   "source": [
    "### Regrouper les DataFrames en un seul DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "303d42ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|Order ID|             Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|  141234|              iPhone|               1|       700|01/22/19 21:25|944 Walnut St, Bo...|\n",
      "|  141235|Lightning Chargin...|               1|     14.95|01/28/19 14:15|185 Maple St, Por...|\n",
      "|  141236|    Wired Headphones|               2|     11.99|01/17/19 13:33|538 Adams St, San...|\n",
      "|  141237|    27in FHD Monitor|               1|    149.99|01/05/19 20:33|738 10th St, Los ...|\n",
      "|  141238|    Wired Headphones|               1|     11.99|01/25/19 11:59|387 10th St, Aust...|\n",
      "|  141239|AAA Batteries (4-...|               1|      2.99|01/29/19 20:22|775 Willow St, Sa...|\n",
      "|  141240|27in 4K Gaming Mo...|               1|    389.99|01/26/19 12:16|979 Park St, Los ...|\n",
      "|  141241|USB-C Charging Cable|               1|     11.95|01/05/19 12:04|181 6th St, San F...|\n",
      "|  141242|Bose SoundSport H...|               1|     99.99|01/01/19 10:30|867 Willow St, Lo...|\n",
      "|  141243|Apple Airpods Hea...|               1|       150|01/22/19 21:20|657 Johnson St, S...|\n",
      "|  141244|Apple Airpods Hea...|               1|       150|01/07/19 11:29|492 Walnut St, Sa...|\n",
      "|  141245|  Macbook Pro Laptop|               1|      1700|01/31/19 10:12|322 6th St, San F...|\n",
      "|  141246|AAA Batteries (4-...|               3|      2.99|01/09/19 18:57|618 7th St, Los A...|\n",
      "|  141247|    27in FHD Monitor|               1|    149.99|01/25/19 19:19|512 Wilson St, Sa...|\n",
      "|  141248|       Flatscreen TV|               1|       300|01/03/19 21:54|363 Spruce St, Au...|\n",
      "|  141249|    27in FHD Monitor|               1|    149.99|01/05/19 17:20|440 Cedar St, Por...|\n",
      "|  141250|     Vareebadd Phone|               1|       400|01/10/19 11:20|471 Center St, Lo...|\n",
      "|  141251|Apple Airpods Hea...|               1|       150|01/24/19 08:13|414 Walnut St, Bo...|\n",
      "|  141252|USB-C Charging Cable|               1|     11.95|01/30/19 09:28|220 9th St, Los A...|\n",
      "|  141253|AA Batteries (4-p...|               1|      3.84|01/17/19 00:09|385 11th St, Atla...|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: string, Product: string ... 4 more fields]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newdf: DataFrame = dfJanuary\n",
    "                        .union(dfFebruary)\n",
    "                        .union(dfMarch)\n",
    "                        .union(dfApril)\n",
    "                        .union(dfMay)\n",
    "                        .union(dfJune)\n",
    "                        .union(dfJuly)\n",
    "                        .union(dfAugust)\n",
    "                        .union(dfSeptembre)\n",
    "                        .union(dfOctober)\n",
    "                        .union(dfNovember)\n",
    "                        .union(dfDecember)\n",
    "newdf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c48f2aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: string (nullable = true)\n",
      " |-- Price Each: string (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a91bfb7",
   "metadata": {},
   "source": [
    "Nous constatons que tout les  variables sont de type string alors que certains devrait etre de type double ou Integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05529be",
   "metadata": {},
   "source": [
    "### Convertir les variables Order ID, Quantity Ordered, et Price Each en type Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b02e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns converted from Integer to Double:\n",
      " - Price Each\n",
      " - Quantity Ordered\n",
      " - Order ID \n",
      "\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">TypeDouble</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">DataFrame</span></span> = [Price Each: string, Quantity Ordered: string ... 1 more field]\n",
       "<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">import </span></span><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">org.apache.spark.sql.types.StringType\n",
       "\n",
       "</span></span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">StringColumns</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Array</span></span>[<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span>] = <span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">Array</span></span>(\n",
       "  <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;Price Each&quot;</span></span>,\n",
       "  <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;Quantity Ordered&quot;</span></span>,\n",
       "  <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;Order ID&quot;</span></span>\n",
       ")\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">doublesDF</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">DataFrame</span></span> = <style>@keyframes fadein { from { opacity: 0; } to { opacity: 1; } }</style><span style=\"animation: fadein 2s;\">[Order ID: double, Product: string ... 6 more fields]</span>\n",
       "<span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">columns</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">String</span></span> = <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">&quot;&quot;&quot;Price Each\n",
       " - Quantity Ordered\n",
       " - Order ID&quot;&quot;&quot;</span></span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mTypeDouble\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Price Each: string, Quantity Ordered: string ... 1 more field]\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types.StringType\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mStringColumns\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"Price Each\"\u001b[39m,\n",
       "  \u001b[32m\"Quantity Ordered\"\u001b[39m,\n",
       "  \u001b[32m\"Order ID\"\u001b[39m\n",
       ")\n",
       "\u001b[36mdoublesDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 6 more fields]\n",
       "\u001b[36mcolumns\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\"Price Each\n",
       " - Quantity Ordered\n",
       " - Order ID\"\"\"\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Selectionner les variables qui doit etre de type double\n",
    "val TypeDouble = newdf2.select(\n",
    "    \"Price Each\",\n",
    "    \"Quantity Ordered\",\n",
    "    \"Order ID\"\n",
    "  )\n",
    "\n",
    "//Convertir ces variables en type double\n",
    "import org.apache.spark.sql.types.StringType\n",
    "\n",
    "val StringColumns = for (x <- TypeDouble.schema.fields if (x.dataType == StringType)) yield x.name  \n",
    "var doublesDF = newdf2\n",
    "\n",
    "for (c <- StringColumns)\n",
    "  doublesDF = doublesDF.withColumn(c, col(c).cast(\"double\"))\n",
    "\n",
    "val columns = StringColumns.mkString(\"\\n - \")\n",
    "println(s\"Columns converted from Integer to Double:\\n - $columns \\n\")\n",
    "println(\"*-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d6d01d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: double (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: double (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doublesDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4db7c405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "|Order ID|             Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|Total Sales|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "|141234.0|              iPhone|             1.0|     700.0|01/22/19 21:25|944 Walnut St, Bo...|      700.0|\n",
      "|141235.0|Lightning Chargin...|             1.0|     14.95|01/28/19 14:15|185 Maple St, Por...|      14.95|\n",
      "|141236.0|    Wired Headphones|             2.0|     11.99|01/17/19 13:33|538 Adams St, San...|      23.98|\n",
      "|141237.0|    27in FHD Monitor|             1.0|    149.99|01/05/19 20:33|738 10th St, Los ...|     149.99|\n",
      "|141238.0|    Wired Headphones|             1.0|     11.99|01/25/19 11:59|387 10th St, Aust...|      11.99|\n",
      "|141239.0|AAA Batteries (4-...|             1.0|      2.99|01/29/19 20:22|775 Willow St, Sa...|       2.99|\n",
      "|141240.0|27in 4K Gaming Mo...|             1.0|    389.99|01/26/19 12:16|979 Park St, Los ...|     389.99|\n",
      "|141241.0|USB-C Charging Cable|             1.0|     11.95|01/05/19 12:04|181 6th St, San F...|      11.95|\n",
      "|141242.0|Bose SoundSport H...|             1.0|     99.99|01/01/19 10:30|867 Willow St, Lo...|      99.99|\n",
      "|141243.0|Apple Airpods Hea...|             1.0|     150.0|01/22/19 21:20|657 Johnson St, S...|      150.0|\n",
      "|141244.0|Apple Airpods Hea...|             1.0|     150.0|01/07/19 11:29|492 Walnut St, Sa...|      150.0|\n",
      "|141245.0|  Macbook Pro Laptop|             1.0|    1700.0|01/31/19 10:12|322 6th St, San F...|     1700.0|\n",
      "|141246.0|AAA Batteries (4-...|             3.0|      2.99|01/09/19 18:57|618 7th St, Los A...|       8.97|\n",
      "|141247.0|    27in FHD Monitor|             1.0|    149.99|01/25/19 19:19|512 Wilson St, Sa...|     149.99|\n",
      "|141248.0|       Flatscreen TV|             1.0|     300.0|01/03/19 21:54|363 Spruce St, Au...|      300.0|\n",
      "|141249.0|    27in FHD Monitor|             1.0|    149.99|01/05/19 17:20|440 Cedar St, Por...|     149.99|\n",
      "|141250.0|     Vareebadd Phone|             1.0|     400.0|01/10/19 11:20|471 Center St, Lo...|      400.0|\n",
      "|141251.0|Apple Airpods Hea...|             1.0|     150.0|01/24/19 08:13|414 Walnut St, Bo...|      150.0|\n",
      "|141252.0|USB-C Charging Cable|             1.0|     11.95|01/30/19 09:28|220 9th St, Los A...|      11.95|\n",
      "|141253.0|AA Batteries (4-p...|             1.0|      3.84|01/17/19 00:09|385 11th St, Atla...|       3.84|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewdf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 5 more fields]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newdf = doublesDF.withColumn(\"Total Sales\", functions.col(\"Quantity Ordered\") * functions.col(\"Price Each\"))\n",
    "newdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f238e43",
   "metadata": {},
   "source": [
    "### Séparation de la colonne \"Purchase Address\" en 2 colonne distincte (Address et Ville)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "64f73c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: double (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: double (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      " |-- Total Sales: double (nullable = true)\n",
      " |-- Address: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Ville: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnewdf1\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 7 more fields]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newdf1 = newdf.withColumn(\"Address\", functions.split(functions.col(\"Purchase Address\"), \",\"))\n",
    "  .withColumn(\"Ville\", functions.split(functions.col(\"Purchase Address\"), \",\") .getItem(1))\n",
    "\n",
    "newdf1.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e6252f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdfDate\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 8 more fields]\n",
       "\u001b[36mdfMonthYear\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 10 more fields]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Convertir la colonne \"Order Date\" en format date(MM/dd/yyyy HH:mm)\n",
    "val dfDate = newdf1.withColumn(\"OrderDate\", functions.to_date(functions.col(\"Order Date\"), \"MM/dd/yyyy HH:mm\"))\n",
    "\n",
    "// Extraire le mois et l'année à partir de la colonne \"OrderDate\"\n",
    "val dfMonthYear = dfDate.withColumn(\"Month\", functions.month(functions.col(\"OrderDate\")))\n",
    "  .withColumn(\"Year\", functions.year(functions.col(\"OrderDate\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ba90d",
   "metadata": {},
   "source": [
    "## Réponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb5d21d",
   "metadata": {},
   "source": [
    "1. Quelle année a été la meilleure en termes de ventes ? Combien a-t-on gagné cette année-là ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5ba6aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'année qui a été la meilleure en termes de ventes est l'année 2019.\n",
      "Le montant total des ventes pour cette année est de 3.3799036410004914E7.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtotalSalesYearly\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Year: int, TotalSales: double]\n",
       "\u001b[36mbestYearRow\u001b[39m: \u001b[32mRow\u001b[39m = [19,3.3799036410004914E7]\n",
       "\u001b[36mbestYear\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m19\u001b[39m\n",
       "\u001b[36mbestYearSale\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m3.3799036410004914E7\u001b[39m"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculer le total des ventes par année\n",
    "val totalSalesYearly = dfMonthYear.groupBy(\"Year\")\n",
    "  .agg(functions.sum(\"Total Sales\").alias(\"TotalSales\"))\n",
    "  .orderBy(functions.desc(\"TotalSales\"))\n",
    "\n",
    "// Obtenir la meilleure année en termes de ventes\n",
    "val bestYearRow = totalSalesYearly.first()\n",
    "val bestYear = bestYearRow.getAs[Int](\"Year\")\n",
    "val bestYearSale = bestYearRow.getAs[Double](\"TotalSales\")\n",
    "\n",
    "// Afficher le résultat\n",
    "println(s\"L'année qui a été la meilleure en termes de ventes est l'année 20$bestYear.\")\n",
    "println(s\"Le montant total des ventes pour cette année est de $bestYearSale.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d5953",
   "metadata": {},
   "source": [
    "2. Quel mois a été le meilleur en termes de ventes ? Combien a-t-on gagné ce mois-là ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b4390c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------------------+\n",
      "|Month|Year|        TotalSales|\n",
      "+-----+----+------------------+\n",
      "|   11|  19| 3715537.459999819|\n",
      "|   10|  19| 3587664.439999961|\n",
      "|    4|  19| 3320523.329999849|\n",
      "|    3|  19| 3043415.159999854|\n",
      "|    5|  19| 2943146.869999862|\n",
      "|   12|  19|2824942.9500003685|\n",
      "|    9|  19|2674799.2499998747|\n",
      "|    6|  19| 2553346.229999885|\n",
      "|    7|  19| 2532465.759999886|\n",
      "|    2|  19| 2345457.729999894|\n",
      "|    8|  19|  2192137.81999991|\n",
      "|    1|  19|2065599.4099999147|\n",
      "|   12|  18| 692999.5599999847|\n",
      "| null|null|              null|\n",
      "+-----+----+------------------+\n",
      "\n",
      "Le meilleur mois en termes de ventes est le mois 11.\n",
      "Le montant total des ventes pour ce mois est de 3715537.459999819.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtotalMonthSales\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Month: int, Year: int ... 1 more field]\n",
       "\u001b[36mbestMonthRow\u001b[39m: \u001b[32mRow\u001b[39m = [11,19,3715537.459999819]\n",
       "\u001b[36mbestMonth\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m11\u001b[39m\n",
       "\u001b[36mbestMonthSales\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m3715537.459999819\u001b[39m"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculer le total des ventes par mois\n",
    "val totalMonthSales = dfMonthYear.groupBy(\"Month\", \"Year\")\n",
    "  .agg(functions.sum(\"Total Sales\").alias(\"TotalSales\"))\n",
    "  .orderBy(functions.desc(\"TotalSales\"))\n",
    "totalMonthSales.show()\n",
    "\n",
    "// Obtenir le meilleur mois en termes de ventes\n",
    "val bestMonthRow = totalMonthSales.first()\n",
    "val bestMonth = bestMonthRow.getAs[Int](\"Month\")\n",
    "val bestMonthSales = bestMonthRow.getAs[Double](\"TotalSales\")\n",
    "\n",
    "// Afficher le résultat\n",
    "println(s\"Le meilleur mois en termes de ventes est le mois $bestMonth.\")\n",
    "println(s\"Le montant total des ventes pour ce mois est de $bestMonthSales.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24c55a",
   "metadata": {},
   "source": [
    "3. Quelle ville a enregistré le plus grand nombre de ventes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "efdd3afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|         Ville|        TotalSales|\n",
      "+--------------+------------------+\n",
      "| San Francisco| 8262203.909999811|\n",
      "|   Los Angeles| 5452570.799999968|\n",
      "| New York City|  4664317.42999998|\n",
      "|        Boston| 3661642.009999992|\n",
      "|       Atlanta|2795498.5799999936|\n",
      "|        Dallas| 2767975.399999994|\n",
      "|       Seattle|2747755.4799999953|\n",
      "|      Portland| 2320490.609999995|\n",
      "|        Austin| 1819581.749999999|\n",
      "|          null|              null|\n",
      "+--------------+------------------+\n",
      "\n",
      "La ville avec le plus grand nombre de ventes est  San Francisco.\n",
      "Le montant total des ventes dans cette ville est de 8262203.909999811.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mcitySales\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Ville: string, TotalSales: double]\n",
       "\u001b[36mbestCityRow\u001b[39m: \u001b[32mRow\u001b[39m = [ San Francisco,8262203.909999811]\n",
       "\u001b[36mbestCity\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\" San Francisco\"\u001b[39m\n",
       "\u001b[36mbestCitySales\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m8262203.909999811\u001b[39m"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculer le total des ventes par ville\n",
    "val citySales = newdf1.groupBy(\"Ville\")\n",
    "  .agg(functions.sum(\"Total Sales\").alias(\"TotalSales\"))\n",
    "  .orderBy(functions.desc(\"TotalSales\"))\n",
    "citySales.show()\n",
    "\n",
    "// Obtenir la ville avec le plus grand nombre de vente\n",
    "val bestCityRow = citySales.first()\n",
    "val bestCity = bestCityRow.getString(0)\n",
    "val bestCitySales = bestCityRow.getDouble(1)\n",
    "\n",
    "// Afficher le résultat\n",
    "println(s\"La ville avec le plus grand nombre de ventes est $bestCity.\")\n",
    "println(s\"Le montant total des ventes dans cette ville est de $bestCitySales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72778667",
   "metadata": {},
   "source": [
    "4. À quelle heure devraient-ils diffuser des publicités pour maximiser les chances que les clients achètent le produit ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a68d9f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+\n",
      "|Hour|QuantityOrdered|\n",
      "+----+---------------+\n",
      "|  19|        14470.0|\n",
      "|  12|        14202.0|\n",
      "|  11|        14005.0|\n",
      "|  18|        13802.0|\n",
      "|  20|        13768.0|\n",
      "|  13|        13685.0|\n",
      "|  14|        12362.0|\n",
      "|  10|        12308.0|\n",
      "|  21|        12244.0|\n",
      "|  17|        12229.0|\n",
      "|  16|        11662.0|\n",
      "|  15|        11391.0|\n",
      "|  22|         9899.0|\n",
      "|   9|         9816.0|\n",
      "|  23|         7065.0|\n",
      "|   8|         7002.0|\n",
      "|   7|         4556.0|\n",
      "|   0|         4428.0|\n",
      "|   6|         2810.0|\n",
      "|   1|         2619.0|\n",
      "|   5|         1493.0|\n",
      "|   2|         1398.0|\n",
      "|   4|          937.0|\n",
      "|   3|          928.0|\n",
      "+----+---------------+\n",
      "only showing top 24 rows\n",
      "\n",
      "L'heure optimale pour diffuser des publicités est à 19 heure.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdfTimestamp\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 8 more fields]\n",
       "\u001b[36mdfHour\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 9 more fields]\n",
       "\u001b[36mhourlySales\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Hour: int, QuantityOrdered: double]\n",
       "\u001b[36mbestHourRow\u001b[39m: \u001b[32mRow\u001b[39m = [19,14470.0]\n",
       "\u001b[36mbestHour\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m19\u001b[39m"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Convertir la colonne \"Order Date\" en format de timestamp\n",
    "val dfTimestamp = newdf1.withColumn(\"Timestamp\", functions.to_timestamp(functions.col(\"Order Date\"), \"MM/dd/yyyy HH:mm\"))\n",
    "\n",
    "// Extraire l'heure à partir du timestamp\n",
    "val dfHour = dfTimestamp.withColumn(\"Hour\", functions.hour(functions.col(\"Timestamp\")))\n",
    "\n",
    "// Calcul du nombre total de Commande pour chaque heure\n",
    "val hourlySales = dfHour.groupBy(\"Hour\")\n",
    "  .agg(functions.sum(\"Quantity Ordered\").alias(\"QuantityOrdered\"))\n",
    "  .orderBy(functions.desc(\"QuantityOrdered\"))\n",
    "\n",
    "hourlySales.show(24)\n",
    "\n",
    "// Obtenir l'heure avec le plus grand nombre de commandes\n",
    "val bestHourRow = hourlySales.first()\n",
    "val bestHour = bestHourRow.getAs[Int](\"Hour\")\n",
    "\n",
    "// Afficher le résultat\n",
    "println(s\"L'heure optimale pour diffuser des publicités est à $bestHour heure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889a7d9",
   "metadata": {},
   "source": [
    "5. Quels produits sont le plus souvent vendus ensemble ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "008e7837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------+\n",
      "|           Produit 1|           Produit 2|Occurrences|\n",
      "+--------------------+--------------------+-----------+\n",
      "|Lightning Chargin...|              iPhone|       1011|\n",
      "|USB-C Charging Cable|        Google Phone|        997|\n",
      "|              iPhone|    Wired Headphones|        462|\n",
      "|    Wired Headphones|        Google Phone|        422|\n",
      "|Apple Airpods Hea...|              iPhone|        373|\n",
      "|     Vareebadd Phone|USB-C Charging Cable|        368|\n",
      "|        Google Phone|Bose SoundSport H...|        228|\n",
      "|USB-C Charging Cable|    Wired Headphones|        203|\n",
      "|     Vareebadd Phone|    Wired Headphones|        149|\n",
      "|Lightning Chargin...|    Wired Headphones|        129|\n",
      "|Lightning Chargin...|AA Batteries (4-p...|        106|\n",
      "|USB-C Charging Cable|Bose SoundSport H...|        102|\n",
      "|Lightning Chargin...|USB-C Charging Cable|        100|\n",
      "|Apple Airpods Hea...|    Wired Headphones|        100|\n",
      "|AAA Batteries (4-...|USB-C Charging Cable|         95|\n",
      "|AAA Batteries (4-...|AA Batteries (4-p...|         87|\n",
      "|AAA Batteries (4-...|    Wired Headphones|         86|\n",
      "|AA Batteries (4-p...|    Wired Headphones|         83|\n",
      "|     Vareebadd Phone|Bose SoundSport H...|         82|\n",
      "|Apple Airpods Hea...|AAA Batteries (4-...|         81|\n",
      "+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[36mdfPair\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Products: array<string>]\n",
       "\u001b[36mPairs\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Produit 1: string, Produit 2: string]\n",
       "\u001b[36mPairCounts\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Produit 1: string, Produit 2: string ... 1 more field]\n",
       "\u001b[36mresult\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Produit 1: string, Produit 2: string ... 1 more field]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val dfPair = dfTimestamp.groupBy(\"Order ID\")\n",
    "  .agg(collect_set(\"Product\").as(\"Products\"))\n",
    "\n",
    "\n",
    "//les paires de produits pour chaque commande\n",
    "val Pairs = dfPair.flatMap { row =>\n",
    "  val products = row.getAs[Seq[String]](\"Products\")\n",
    "  products.combinations(2).map(pair => (pair(0), pair(1)))\n",
    "}.toDF(\"Produit 1\", \"Produit 2\")\n",
    "\n",
    "\n",
    "// Le nombre d'occurrences des paires de produits\n",
    "val PairCounts = Pairs.groupBy(\"Produit 1\", \"Produit 2\")\n",
    "  .count()\n",
    "  .withColumn(\"Occurrences\", col(\"count\").cast(\"Int\"))\n",
    "  .drop(\"count\")\n",
    "\n",
    "\n",
    "// Trier\n",
    "val result = PairCounts.orderBy(col(\"Occurrences\").desc)\n",
    "\n",
    "// Afficher le résultat \n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2fc9e",
   "metadata": {},
   "source": [
    "6. Quel produit s'est le plus vendu ? Pourquoi pensez-vous qu'il se soit autant vendu ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "099145a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|             Product|QuantityOrdered|\n",
      "+--------------------+---------------+\n",
      "|AAA Batteries (4-...|        31017.0|\n",
      "|AA Batteries (4-p...|        27635.0|\n",
      "|USB-C Charging Cable|        23975.0|\n",
      "|Lightning Chargin...|        23217.0|\n",
      "|    Wired Headphones|        20557.0|\n",
      "|Apple Airpods Hea...|        15661.0|\n",
      "|Bose SoundSport H...|        13457.0|\n",
      "|    27in FHD Monitor|         7550.0|\n",
      "|              iPhone|         6849.0|\n",
      "|27in 4K Gaming Mo...|         6244.0|\n",
      "|34in Ultrawide Mo...|         6199.0|\n",
      "|        Google Phone|         5532.0|\n",
      "|       Flatscreen TV|         4819.0|\n",
      "|  Macbook Pro Laptop|         4728.0|\n",
      "|     ThinkPad Laptop|         4130.0|\n",
      "|        20in Monitor|         4129.0|\n",
      "|     Vareebadd Phone|         2068.0|\n",
      "|  LG Washing Machine|          666.0|\n",
      "|            LG Dryer|          646.0|\n",
      "|                null|           null|\n",
      "+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Le produit le plus vendu est: AAA Batteries (4-pack).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mproductSales\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Product: string, QuantityOrdered: double]\n",
       "\u001b[36mbestProductRow\u001b[39m: \u001b[32mRow\u001b[39m = [AAA Batteries (4-pack),31017.0]\n",
       "\u001b[36mbestProduct\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"AAA Batteries (4-pack)\"\u001b[39m\n",
       "\u001b[36mbestProductSale\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m31017.0\u001b[39m"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculer le nombre total de ventes pour chaque produit\n",
    "val productSales = newdf1.groupBy(\"Product\")\n",
    "  .agg(functions.sum(\"Quantity Ordered\").alias(\"QuantityOrdered\"))\n",
    "  .orderBy(functions.desc(\"QuantityOrdered\"))\n",
    "productSales.show()\n",
    "\n",
    "// Obtenir le produit avec le plus grand nombre de commandes\n",
    "val bestProductRow = productSales.first()\n",
    "val bestProduct = bestProductRow.getString(0)\n",
    "val bestProductSale = bestProductRow.getDouble(1)\n",
    "\n",
    "// Afficher le résultat\n",
    "println(s\"Le produit le plus vendu est: $bestProduct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e3708",
   "metadata": {},
   "source": [
    "7. Quelle est la probabilité que les prochains clients commandent un câble de chargement USB-C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b04eddfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilité que les prochains clients commandent un câble de chargement USB-C est de 0.11722237088573723%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36musbOrders\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m21903L\u001b[39m\n",
       "\u001b[36mtotalOrders\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m186850L\u001b[39m\n",
       "\u001b[36mprobabilityOrderUsb\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.11722237088573723\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filtrer les commandes de câbles de chargement USB-C\n",
    "val usbOrders = newdf1.filter(newdf1(\"Product\") === \"USB-C Charging Cable\").count\n",
    "\n",
    "// Calculer le nombre total de commandes\n",
    "val totalOrders = newdf1.count()\n",
    "\n",
    "// Calculer la probabilité\n",
    "val probabilityOrderUsb = usbOrders.toDouble / totalOrders.toDouble\n",
    "\n",
    "// Afficher la probabilité\n",
    "println(s\"La probabilité que les prochains clients commandent un câble de chargement USB-C est de $probabilityOrderUsb%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f997d115",
   "metadata": {},
   "source": [
    "8. Quelle est la probabilité que les prochains clients commandent un iPhone ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36837338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilité que les prochains clients commandent un Iphone est de 0.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36miphoneOrders\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m0L\u001b[39m\n",
       "\u001b[36mtotalIphone\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m186850L\u001b[39m\n",
       "\u001b[36mprobabilityOrderIphone\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.0\u001b[39m"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filtrer les commandes d'Iphone\n",
    "val iphoneOrders = newdf1.filter(newdf1(\"Product\") === \"iphone\").count\n",
    "\n",
    "// Calculer le nombre total de commandes\n",
    "val totalIphone = newdf1.count()\n",
    "\n",
    "// Calculer la probabilité\n",
    "val probabilityOrderIphone = iphoneOrders.toDouble / totalIphone.toDouble\n",
    "\n",
    "// Afficher la probabilité\n",
    "println(s\"La probabilité que les prochains clients commandent un Iphone est de $probabilityOrderIphone%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ccc35",
   "metadata": {},
   "source": [
    "9. Quelle est la probabilité que les prochains clients commandent un téléphone Google ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13335197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilité que les prochains clients commandent un Iphone est de 0.02956917313352957%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mgooglePhoneOrders\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m5525L\u001b[39m\n",
       "\u001b[36mtotalGooglePhone\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m186850L\u001b[39m\n",
       "\u001b[36mprobabilityOrderGooglePhone\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.02956917313352957\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filtrer les commandes de Téléphone Google\n",
    "val googlePhoneOrders = newdf1.filter(newdf1(\"Product\") === \"Google Phone\").count\n",
    "\n",
    "// Calculer le nombre total de commandes\n",
    "val totalGooglePhone = newdf1.count()\n",
    "\n",
    "// Calculer la probabilité\n",
    "val probabilityOrderGooglePhone = googlePhoneOrders.toDouble / totalGooglePhone.toDouble\n",
    "\n",
    "// Afficher la probabilité\n",
    "println(s\"La probabilité que les prochains clients commandent un téléphone Google est de $probabilityOrderGooglePhone%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca578681",
   "metadata": {},
   "source": [
    "10. Quelle est la probabilité que d'autres personnes commandent des écouteurs filaires ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf2dcd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La probabilité que les prochains clients commandent un écouteur filaire est de 0.10105432164838106%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mwiredHeadphonesOrders\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m18882L\u001b[39m\n",
       "\u001b[36mtotalWiredHeadphones\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m186850L\u001b[39m\n",
       "\u001b[36mprobabilityWiredHeadphones\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.10105432164838106\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Filtrer les commandes des écouteurs filaires \n",
    "val wiredHeadphonesOrders = newdf1.filter(newdf1(\"Product\") === \"Wired Headphones\").count\n",
    "\n",
    "// Calculer le nombre total de commandes\n",
    "val totalWiredHeadphones = newdf1.count()\n",
    "\n",
    "// Calculer la probabilité\n",
    "val probabilityWiredHeadphones = wiredHeadphonesOrders.toDouble / totalGooglePhone.toDouble\n",
    "\n",
    "// Afficher la probabilité\n",
    "println(s\"La probabilité que les prochains clients commandent un écouteur filaire est de $probabilityWiredHeadphones%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75584e19",
   "metadata": {},
   "source": [
    "## Pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c69ea",
   "metadata": {},
   "source": [
    "Proposer un cas d'utilisation concret de Machine Learning en utilisant cet ensemble de\n",
    "données de ventes. Vous devrez identifier un problème spécifique et proposer un modèle\n",
    "prédictif ou analytique qui peut être utilisé pour résoudre le problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41378f7f",
   "metadata": {},
   "source": [
    "### Etape a suivre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c12958",
   "metadata": {},
   "source": [
    "- Préparation des données : pretaitement des valeurs manquantes, en éliminant les valeurs aberrantes si nécessaire, et en transformant les variables catégorielles en variables numériques si possible.\n",
    "\n",
    "- Séparation des données : Divisez l'ensemble de données en un ensemble d'entraînement et un ensemble de test. L'ensemble d'entraînement sera utilisé pour ajuster le modèle, tandis que l'ensemble de test sera utilisé pour évaluer les performances du modèle sur des données non vues.\n",
    "\n",
    "- Sélection des variables : Identifier les variables pertinentes qui peuvent influencer la demande des ventes. Cela peut inclure des variables telles que la quantité commandée, le prix unitaire, les informations temporelles (mois, jour de la semaine, etc.), etc.\n",
    "\n",
    "- Entraînement du modèle : Appliquer la régression linéaire en ajustant un modèle linéaire aux données d'entraînement. \n",
    "\n",
    "- Évaluation du modèle : Évaluer les performances du modèle en utilisant l'ensemble de test. Nous pouvons utiliser des métriques telles que l'erreur quadratique moyenne (RMSE), l'erreur absolue moyenne (MAE), le coefficient de détermination (R²) pour mesurer la précision et l'adéquation du modèle.\n",
    "\n",
    "- Prédiction de la demande future : Une fois que nous avons évalué et validé notre modèle, vous pouvons l'utiliser pour prédire la demande future en fournissant les valeurs des variables indépendantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77bf09",
   "metadata": {},
   "source": [
    "### Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428d9b2",
   "metadata": {},
   "source": [
    "Notre objectif est de construire un modèle permettant de prédire les performances de ventes future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab91734",
   "metadata": {},
   "source": [
    "### Machine learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0d144",
   "metadata": {},
   "source": [
    "Il s'agit d'un problème de régression, car le prix des ventes est une variable continue. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3259e",
   "metadata": {},
   "source": [
    "### Source de donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d71370",
   "metadata": {},
   "source": [
    "Nous avons juger pertinent d'utiliser l'ensemble des données sur les ventes provenant d'Amazon. Il contient des informations sur les ventes réalisé par Amazon, telles que Le type de produit qui a été vendu, La quantité commandée est la quantité totale d'articles commandés, Le prix de chaque produit, la date à laquelle le client demande que la commande soit expédiée et l'adresse de livraison. Ces donnees sont telechargeable sur Google Classroom. Cependant nous les avons deja telecharge et placer dans le repertoire data du cours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d631d2",
   "metadata": {},
   "source": [
    "### Selection empirique de features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a87b4",
   "metadata": {},
   "source": [
    "Nous allons conserver que les colonnes qui nous semblent pertinentes pour notre analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "418c6519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+----------+-----------+\n",
      "|Order ID|Quantity Ordered|Price Each|Total Sales|\n",
      "+--------+----------------+----------+-----------+\n",
      "|141234.0|             1.0|     700.0|      700.0|\n",
      "|141235.0|             1.0|     14.95|      14.95|\n",
      "|141236.0|             2.0|     11.99|      23.98|\n",
      "|141237.0|             1.0|    149.99|     149.99|\n",
      "|141238.0|             1.0|     11.99|      11.99|\n",
      "|141239.0|             1.0|      2.99|       2.99|\n",
      "|141240.0|             1.0|    389.99|     389.99|\n",
      "|141241.0|             1.0|     11.95|      11.95|\n",
      "|141242.0|             1.0|     99.99|      99.99|\n",
      "|141243.0|             1.0|     150.0|      150.0|\n",
      "|141244.0|             1.0|     150.0|      150.0|\n",
      "|141245.0|             1.0|    1700.0|     1700.0|\n",
      "|141246.0|             3.0|      2.99|       8.97|\n",
      "|141247.0|             1.0|    149.99|     149.99|\n",
      "|141248.0|             1.0|     300.0|      300.0|\n",
      "|141249.0|             1.0|    149.99|     149.99|\n",
      "|141250.0|             1.0|     400.0|      400.0|\n",
      "|141251.0|             1.0|     150.0|      150.0|\n",
      "|141252.0|             1.0|     11.95|      11.95|\n",
      "|141253.0|             1.0|      3.84|       3.84|\n",
      "+--------+----------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf1.select(\n",
    "    \"Order ID\",\n",
    "    \"Quantity Ordered\",\n",
    "    \"Price Each\",\n",
    "    \"Total Sales\",\n",
    ").show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7cb7de",
   "metadata": {},
   "source": [
    "### Preprocessing des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60107b",
   "metadata": {},
   "source": [
    "#### Statistiques sommaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d80ac2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------+-------------------+------------------+--------------+-----------------+\n",
      "|summary|         Order ID|     Product|   Quantity Ordered|        Price Each|    Order Date|      Total Sales|\n",
      "+-------+-----------------+------------+-------------------+------------------+--------------+-----------------+\n",
      "|  count|           185950|      186305|             185950|            185950|        186305|           185950|\n",
      "|   mean|230417.5693788653|        null| 1.1243828986286637|184.39973476743927|          null|185.4909167518412|\n",
      "| stddev|51512.73710999596|        null|0.44279262402866965| 332.7313298843437|          null|332.9197713864793|\n",
      "|    min|         141234.0|20in Monitor|                1.0|              2.99|01/01/19 03:07|             2.99|\n",
      "|    25%|         185815.0|        null|                1.0|             11.95|          null|            11.95|\n",
      "|    50%|         230355.0|        null|                1.0|             14.95|          null|            14.95|\n",
      "|    75%|         275038.0|        null|                1.0|             150.0|          null|            150.0|\n",
      "|    max|         319670.0|      iPhone|                9.0|            1700.0|    Order Date|           3400.0|\n",
      "+-------+-----------------+------------+-------------------+------------------+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newdf1.select(\n",
    "    \"Order ID\",\n",
    "    \"Product\",\n",
    "    \"Quantity Ordered\",\n",
    "    \"Price Each\",\n",
    "    \"Order Date\",\n",
    "    \"Total Sales\",\n",
    "  )\n",
    "  .summary()\n",
    "  .show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350b4a1",
   "metadata": {},
   "source": [
    "D'après le tableau fourni, il semble y avoir des données manquantes dans la colonne \"Product\" et dans la colonne \"Order Date\". Cela est indiqué par la présence de la valeur \"null\" dans les statistiques sommaires pour ces deux variables.\n",
    "\n",
    "En ce qui concerne les autres variables, telles que l'identifiant de commande (\"Order ID\"), la quantité commandée (\"Quantity Ordered\"), le prix unitaire (\"Price Each\") et le chiffre d'affaires total (\"Total Sales\"), toutes les valeurs semblent être disponibles et complètes, car il n'y a pas de mention de \"null\" dans les statistiques sommaires pour ces variables.\n",
    "\n",
    "Cependant, il convient de noter qu'il y a une différence de comptage entre le nombre total d'observations pour \"Order ID\" (186 305) et le nombre d'observations pour \"Total Sales\" (185 950). Cela suggère qu'il pourrait y avoir des valeurs manquantes ou des données non disponibles pour certaines commandes dans la colonne \"Total Sales\".\n",
    "\n",
    "Pour une évaluation plus précise de la présence de données manquantes, il serait recommandé d'examiner de plus près les données brutes pour identifier les valeurs manquantes ou les motifs éventuels de données manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b0e12b",
   "metadata": {},
   "source": [
    "#### Gestion des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d15e25ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres143\u001b[39m: \u001b[32mtypes\u001b[39m.\u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Order ID\"\u001b[39m, DoubleType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Product\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Quantity Ordered\"\u001b[39m, DoubleType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Price Each\"\u001b[39m, DoubleType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Order Date\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Purchase Address\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Total Sales\"\u001b[39m, DoubleType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Address\"\u001b[39m, \u001b[33mArrayType\u001b[39m(StringType, true), true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Ville\"\u001b[39m, StringType, true, {})\n",
       ")"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Verification du type des variables\n",
    "newdf1.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c9f3bd",
   "metadata": {},
   "source": [
    "#### Identification des colonnes manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "744b87eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre total de lignes dans le DataFrame est : 186850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mrowCount\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m186850L\u001b[39m"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rowCount = newdf1.count()\n",
    "println(s\"Le nombre total de lignes dans le DataFrame est : $rowCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f299ece4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres119\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mLong\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m\"Order ID\"\u001b[39m, \u001b[32m900L\u001b[39m),\n",
       "  (\u001b[32m\"Product\"\u001b[39m, \u001b[32m545L\u001b[39m),\n",
       "  (\u001b[32m\"Quantity Ordered\"\u001b[39m, \u001b[32m900L\u001b[39m),\n",
       "  (\u001b[32m\"Price Each\"\u001b[39m, \u001b[32m900L\u001b[39m),\n",
       "  (\u001b[32m\"Order Date\"\u001b[39m, \u001b[32m545L\u001b[39m),\n",
       "  (\u001b[32m\"Purchase Address\"\u001b[39m, \u001b[32m545L\u001b[39m),\n",
       "  (\u001b[32m\"Total Sales\"\u001b[39m, \u001b[32m900L\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.columns.map(c => (c, newdf.filter(col(c).isNull || col(c).isNaN).count()))\n",
    "    .filter(_._2 > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2924c",
   "metadata": {},
   "source": [
    "Les colonnes: Product,Order Date,Purchase Address et Total Sales ont des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbfea62",
   "metadata": {},
   "source": [
    "##### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d64036b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmissingCols\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"Order ID\"\u001b[39m,\n",
       "  \u001b[32m\"Product\"\u001b[39m,\n",
       "  \u001b[32m\"Quantity Ordered\"\u001b[39m,\n",
       "  \u001b[32m\"Price Each\"\u001b[39m,\n",
       "  \u001b[32m\"Order Date\"\u001b[39m,\n",
       "  \u001b[32m\"Purchase Address\"\u001b[39m,\n",
       "  \u001b[32m\"Total Sales\"\u001b[39m\n",
       ")\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.when\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Ajoutez une variable fictive si nous voulons imputer une valeur.\n",
    "val missingCols = newdf.columns.map(c => (c, newdf.filter(col(c).isNull || col(c).isNaN).count()))\n",
    "    .filter(_._2 > 0)\n",
    "    .map(_._1)\n",
    "\n",
    "import org.apache.spark.sql.functions.when\n",
    "\n",
    "for (c <- missingCols)\n",
    "  doublesDF = newdf.withColumn(c + \"_na\", when(col(c).isNull, 1.0).otherwise(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92948c10",
   "metadata": {},
   "source": [
    "Ajoutons de nouvelles colonnes au DataFrame doublesDF pour chaque colonne dans missingCols afin de marquer les valeurs nulles (null) avec 1.0 et les valeurs non nulles avec 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fa79f016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: double (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: double (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      " |-- Total Sales: double (nullable = true)\n",
      " |-- Total Sales_na: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.when\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.when\n",
    "\n",
    "for (c <- missingCols)\n",
    "  doublesDF = newdf.withColumn(c + \"_na\", when(col(c).isNull, 1.0).otherwise(0.0))\n",
    "doublesDF.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447b15cc",
   "metadata": {},
   "source": [
    "Imputons par la medianne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "534412a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.feature.Imputer\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mimputeCols\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"Order ID\"\u001b[39m,\n",
       "  \u001b[32m\"Quantity Ordered\"\u001b[39m,\n",
       "  \u001b[32m\"Price Each\"\u001b[39m,\n",
       "  \u001b[32m\"Total Sales\"\u001b[39m\n",
       ")\n",
       "\u001b[36mimputer\u001b[39m: \u001b[32mImputer\u001b[39m = imputer_1d93e25c9d0c\n",
       "\u001b[36mimputedDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 5 more fields]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.Imputer\n",
    "\n",
    "val imputeCols = Array(\"Order ID\",\"Quantity Ordered\",\"Price Each\", \"Total Sales\")\n",
    "\n",
    "val imputer = new Imputer()\n",
    "  .setStrategy(\"median\")\n",
    "  .setInputCols(imputeCols)\n",
    "  .setOutputCols(imputeCols)\n",
    "\n",
    "val imputedDF = imputer.fit(newdf).transform(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputedDF.columns.map(c => (c, imputedDF.filter(col(c).isNull || col(c).isNaN).count()))\n",
    "    .filter(_._2 > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f357a12",
   "metadata": {},
   "source": [
    "##### Separtion des données en donnée d’entraînement(training) et des donnée de test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cd2f0",
   "metadata": {},
   "source": [
    "L'ensemble d'entraînement sera utilisé pour entraîner le modèle, tandis que l'ensemble de test sera utilisé pour évaluer les performances du modèle sur des données non vues. Ainsi nous allons garder:<br>\n",
    "- 80% pour le training et réservons <br>\n",
    "- 20% de nos données pour le test. <br><br>\n",
    "Nous utiliserons la méthode `randomSplit()` pour cela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fb6dcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/26 23:03:05 WARN CacheManager: Asked to cache already cached data.\n",
      "23/05/26 23:03:05 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y'a 149410 lignes dans le training set, et 37440 dans le test set\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainDF\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Order ID: double, Product: string ... 5 more fields]\n",
       "\u001b[36mtestDF\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [Order ID: double, Product: string ... 5 more fields]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(trainDF, testDF) = imputedDF.randomSplit(Array(.8, .2), seed=28)\n",
    "println(f\"Il y'a ${trainDF.cache().count()} lignes dans le training set, et ${testDF.cache().count()} dans le test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a6435",
   "metadata": {},
   "source": [
    "##### Preparation des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7366241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+-----------+\n",
      "|Quantity Ordered|features|Total Sales|\n",
      "+----------------+--------+-----------+\n",
      "|             1.0|   [1.0]|      700.0|\n",
      "|             1.0|   [1.0]|      14.95|\n",
      "|             1.0|   [1.0]|      11.99|\n",
      "|             1.0|   [1.0]|     389.99|\n",
      "|             1.0|   [1.0]|      99.99|\n",
      "|             1.0|   [1.0]|      150.0|\n",
      "|             1.0|   [1.0]|      150.0|\n",
      "|             1.0|   [1.0]|     1700.0|\n",
      "|             1.0|   [1.0]|     149.99|\n",
      "|             1.0|   [1.0]|      300.0|\n",
      "+----------------+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.feature.VectorAssembler\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mvecAssembler\u001b[39m: \u001b[32mVectorAssembler\u001b[39m = vecAssembler_eddb80c8b8a8\n",
       "\u001b[36mvecTrainDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 6 more fields]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "\n",
    "val vecAssembler = new VectorAssembler()\n",
    "  .setInputCols(Array(\"Quantity Ordered\"))\n",
    "  .setOutputCol(\"features\")\n",
    "\n",
    "val vecTrainDF = vecAssembler.transform(trainDF)\n",
    "\n",
    "vecTrainDF\n",
    "  .select(\"Quantity Ordered\",\"features\",\"Total Sales\")\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b60272",
   "metadata": {},
   "source": [
    "##### Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5c053",
   "metadata": {},
   "source": [
    "Dans ce projet, nous voulons ajuster un modèle de régression linéaire pour prédire le montant des ventes en fonction du nombre de commande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48543330",
   "metadata": {},
   "source": [
    "###### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "beeca86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/26 23:07:38 WARN Instrumentation: [49cb7b90] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.regression.LinearRegression\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mlr\u001b[39m: \u001b[32mLinearRegression\u001b[39m = linReg_bb59fe09d259\n",
       "\u001b[36mlrModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mregression\u001b[39m.\u001b[32mLinearRegressionModel\u001b[39m = linReg_bb59fe09d259"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "\n",
    "val lr = new LinearRegression()\n",
    "  .setFeaturesCol(\"features\")\n",
    "  .setLabelCol(\"Total Sales\")\n",
    "\n",
    "val lrModel = lr.fit(vecTrainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324a82f",
   "metadata": {},
   "source": [
    "Examinons le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "568a8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La formule de la ligne de régression linéaire est le prix = -104.59*Total Sales + 302.66\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mm\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m-104.58567230574222\u001b[39m\n",
       "\u001b[36mb\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m302.65986592143605\u001b[39m"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val m = lrModel.coefficients(0)\n",
    "val b = lrModel.intercept\n",
    "\n",
    "println(f\"La formule de la ligne de régression linéaire est le prix = $m%1.2f*Total Sales + $b%1.2f\")\n",
    "println(\"*-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2be68a",
   "metadata": {},
   "source": [
    "###### Création d'un pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "373e30d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/26 23:07:51 WARN Instrumentation: [a6ad0632] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.Pipeline\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mpipeline\u001b[39m: \u001b[32mPipeline\u001b[39m = pipeline_e0383847ed70\n",
       "\u001b[36mpipelineModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mPipelineModel\u001b[39m = pipeline_e0383847ed70"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.Pipeline\n",
    "\n",
    "val pipeline = new Pipeline().setStages(Array(vecAssembler, lr))\n",
    "val pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f2540ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+-----------+-------------------+\n",
      "|Quantity Ordered|features|Total Sales|         prediction|\n",
      "+----------------+--------+-----------+-------------------+\n",
      "|             2.0|   [2.0]|      23.98|  93.48852130995161|\n",
      "|             1.0|   [1.0]|     149.99| 198.07419361569384|\n",
      "|             1.0|   [1.0]|       2.99| 198.07419361569384|\n",
      "|             1.0|   [1.0]|      11.95| 198.07419361569384|\n",
      "|             3.0|   [3.0]|       8.97|-11.097150995790628|\n",
      "|             1.0|   [1.0]|      11.95| 198.07419361569384|\n",
      "|             1.0|   [1.0]|       3.84| 198.07419361569384|\n",
      "|             1.0|   [1.0]|      11.95| 198.07419361569384|\n",
      "|             1.0|   [1.0]|      99.99| 198.07419361569384|\n",
      "|             1.0|   [1.0]|      150.0| 198.07419361569384|\n",
      "+----------------+--------+-----------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mpredDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 7 more fields]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predDF = pipelineModel.transform(testDF)\n",
    "\n",
    "predDF\n",
    "  .select(\"Quantity Ordered\",\"features\", \"Total Sales\", \"prediction\")\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4318289",
   "metadata": {},
   "source": [
    "###### Évaluation du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aa2f31",
   "metadata": {},
   "source": [
    "Nous utiliserons l'erreur quadratique moyenne ($RMSE$) et $R^2$ (prononcé \"*R-scared*\") pour évaluer la performance de notre modèle.<br>\n",
    "$$RMSE = \\sqrt{\\frac{1}{n}\\Sigma_{i=1}^{n}\\Big({y_i -\\hat{y_i}}\\Big)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "019839f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.evaluation.RegressionEvaluator \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mregressionEvaluator\u001b[39m: \u001b[32mRegressionEvaluator\u001b[39m = regEval_440f84b5695a\n",
       "\u001b[36mrmse\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m325.50468389560524\u001b[39m"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator \n",
    "\n",
    "val regressionEvaluator = new RegressionEvaluator()\n",
    "  .setPredictionCol(\"prediction\")\n",
    "  .setLabelCol(\"Total Sales\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "val rmse = regressionEvaluator.evaluate(predDF) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7357a",
   "metadata": {},
   "source": [
    "###### Interpretation de la RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d0140",
   "metadata": {},
   "source": [
    "Nous utiliserons la méthode des $R^2$ pour interpréter cette valeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "93c31b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 est 0.019139918581469795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mr2\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.019139918581469795\u001b[39m"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r2 = regressionEvaluator\n",
    "  .setMetricName(\"r2\")\n",
    "  .evaluate(predDF) \n",
    "\n",
    "println(s\"R2 est $r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97886cfd",
   "metadata": {},
   "source": [
    "###### Modele de reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50238e59",
   "metadata": {},
   "source": [
    "Calculons le prix moyen sur le training set, et utilisons cela comme colonne de prédiction pour notre ensemble de données de test, puis évaluons le résultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "a2a90db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+------------------+\n",
      "|Quantity Ordered|Total Sales|     avgPrediction|\n",
      "+----------------+-----------+------------------+\n",
      "|             2.0|      23.98|185.10825821565862|\n",
      "|             1.0|     149.99|185.10825821565862|\n",
      "|             1.0|       2.99|185.10825821565862|\n",
      "|             1.0|      11.95|185.10825821565862|\n",
      "|             3.0|       8.97|185.10825821565862|\n",
      "|             1.0|      11.95|185.10825821565862|\n",
      "|             1.0|       3.84|185.10825821565862|\n",
      "|             1.0|      11.95|185.10825821565862|\n",
      "|             1.0|      99.99|185.10825821565862|\n",
      "|             1.0|      150.0|185.10825821565862|\n",
      "+----------------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions.{avg, lit}\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mavgPrice\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m185.10825821565862\u001b[39m\n",
       "\u001b[36mpredBaseLineDF\u001b[39m: \u001b[32mDataFrame\u001b[39m = [Order ID: double, Product: string ... 6 more fields]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{avg, lit}\n",
    "\n",
    "val avgPrice = trainDF\n",
    "  .select(avg(\"Total Sales\"))\n",
    "  .first()\n",
    "  .getDouble(0)\n",
    "\n",
    "val predBaseLineDF = testDF.withColumn(\"avgPrediction\", lit(avgPrice))\n",
    "\n",
    "predBaseLineDF\n",
    "  .select(\"Quantity Ordered\", \"Total Sales\", \"avgPrediction\")\n",
    "  .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8180051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le RMSE pour prédire le prix moyen est: 328.67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.evaluation.RegressionEvaluator\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mregressionMeanEvaluator\u001b[39m: \u001b[32mRegressionEvaluator\u001b[39m = regEval_c6a62b22616a\n",
       "\u001b[36mrmseBaseLine\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m328.6724875297801\u001b[39m"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.evaluation.RegressionEvaluator\n",
    "\n",
    "val regressionMeanEvaluator = new RegressionEvaluator()\n",
    "  .setPredictionCol(\"avgPrediction\")\n",
    "  .setLabelCol(\"Total Sales\")\n",
    "  .setMetricName(\"rmse\")\n",
    "\n",
    "val rmseBaseLine = regressionMeanEvaluator.evaluate(predBaseLineDF)\n",
    "println (f\"Le RMSE pour prédire le prix moyen est: $rmseBaseLine%1.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "7dfb2090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 BaseLine est -4.439271514700138E-5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mr2BaseLine\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m-4.439271514700138E-5\u001b[39m"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val r2BaseLine = regressionMeanEvaluator\n",
    "  .setMetricName(\"r2\")\n",
    "  .evaluate(predBaseLineDF) \n",
    "\n",
    "println(s\"R2 BaseLine est $r2BaseLine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d41518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
